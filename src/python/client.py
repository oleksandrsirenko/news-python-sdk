# This file was auto-generated by Fern from our API Definition.

import typing

import httpx

from .core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from .environment import NewscatcherApiEnvironment
from .resources.aggregation.client import AggregationClient, AsyncAggregationClient
from .resources.authors.client import AsyncAuthorsClient, AuthorsClient
from .resources.latestheadlines.client import AsyncLatestheadlinesClient, LatestheadlinesClient
from .resources.search.client import AsyncSearchClient, SearchClient
from .resources.searchlink.client import AsyncSearchlinkClient, SearchlinkClient
from .resources.searchsimilar.client import AsyncSearchsimilarClient, SearchsimilarClient
from .resources.sources.client import AsyncSourcesClient, SourcesClient
from .resources.subscription.client import AsyncSubscriptionClient, SubscriptionClient


class NewscatcherApi:
    def __init__(
        self,
        *,
        base_url: typing.Optional[str] = None,
        environment: NewscatcherApiEnvironment = NewscatcherApiEnvironment.DEFAULT,
        api_key: str,
        timeout: typing.Optional[float] = 60,
        httpx_client: typing.Optional[httpx.Client] = None
    ):
        self._client_wrapper = SyncClientWrapper(
            base_url=_get_base_url(base_url=base_url, environment=environment),
            api_key=api_key,
            httpx_client=httpx.Client(timeout=timeout) if httpx_client is None else httpx_client,
        )
        self.search = SearchClient(client_wrapper=self._client_wrapper)
        self.latestheadlines = LatestheadlinesClient(client_wrapper=self._client_wrapper)
        self.authors = AuthorsClient(client_wrapper=self._client_wrapper)
        self.searchlink = SearchlinkClient(client_wrapper=self._client_wrapper)
        self.searchsimilar = SearchsimilarClient(client_wrapper=self._client_wrapper)
        self.sources = SourcesClient(client_wrapper=self._client_wrapper)
        self.aggregation = AggregationClient(client_wrapper=self._client_wrapper)
        self.subscription = SubscriptionClient(client_wrapper=self._client_wrapper)


class AsyncNewscatcherApi:
    def __init__(
        self,
        *,
        base_url: typing.Optional[str] = None,
        environment: NewscatcherApiEnvironment = NewscatcherApiEnvironment.DEFAULT,
        api_key: str,
        timeout: typing.Optional[float] = 60,
        httpx_client: typing.Optional[httpx.AsyncClient] = None
    ):
        self._client_wrapper = AsyncClientWrapper(
            base_url=_get_base_url(base_url=base_url, environment=environment),
            api_key=api_key,
            httpx_client=httpx.AsyncClient(timeout=timeout) if httpx_client is None else httpx_client,
        )
        self.search = AsyncSearchClient(client_wrapper=self._client_wrapper)
        self.latestheadlines = AsyncLatestheadlinesClient(client_wrapper=self._client_wrapper)
        self.authors = AsyncAuthorsClient(client_wrapper=self._client_wrapper)
        self.searchlink = AsyncSearchlinkClient(client_wrapper=self._client_wrapper)
        self.searchsimilar = AsyncSearchsimilarClient(client_wrapper=self._client_wrapper)
        self.sources = AsyncSourcesClient(client_wrapper=self._client_wrapper)
        self.aggregation = AsyncAggregationClient(client_wrapper=self._client_wrapper)
        self.subscription = AsyncSubscriptionClient(client_wrapper=self._client_wrapper)


def _get_base_url(*, base_url: typing.Optional[str] = None, environment: NewscatcherApiEnvironment) -> str:
    if base_url is not None:
        return base_url
    elif environment is not None:
        return environment.value
    else:
        raise Exception("Please pass in either base_url or environment to construct the client")
